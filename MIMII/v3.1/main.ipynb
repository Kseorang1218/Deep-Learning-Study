{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/0_dB/fan.zip already exist.\n",
      "./data/0_dB/fan.zip already extracted.\n",
      "./data/0_dB/pump.zip already exist.\n",
      "./data/0_dB/pump.zip already extracted.\n",
      "./data/0_dB/slider.zip already exist.\n",
      "./data/0_dB/slider.zip already extracted.\n",
      "./data/0_dB/valve.zip already exist.\n",
      "./data/0_dB/valve.zip already extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fan - id_00 - abnormal: 407it [00:02, 147.91it/s]\n",
      "Processing fan - id_00 - normal: 1011it [00:05, 178.71it/s]\n",
      "Processing fan - id_02 - abnormal: 359it [00:02, 177.64it/s]\n",
      "Processing fan - id_02 - normal: 1016it [00:05, 179.71it/s]\n",
      "Processing fan - id_04 - abnormal: 348it [00:01, 186.06it/s]\n",
      "Processing fan - id_04 - normal: 1033it [00:05, 179.97it/s]\n",
      "Processing fan - id_06 - abnormal: 361it [00:02, 176.27it/s]\n",
      "Processing fan - id_06 - normal: 1015it [00:05, 177.18it/s]\n",
      "Processing pump - id_00 - abnormal: 143it [00:00, 180.46it/s]\n",
      "Processing pump - id_00 - normal: 1006it [00:05, 177.86it/s]\n",
      "Processing pump - id_02 - abnormal: 111it [00:00, 182.45it/s]\n",
      "Processing pump - id_02 - normal: 1005it [00:05, 175.82it/s]\n",
      "Processing pump - id_04 - abnormal: 100it [00:00, 179.27it/s]\n",
      "Processing pump - id_04 - normal: 702it [00:03, 175.94it/s]\n",
      "Processing pump - id_06 - abnormal: 102it [00:00, 183.48it/s]\n",
      "Processing pump - id_06 - normal: 1036it [00:05, 176.74it/s]\n",
      "Processing slider - id_00 - abnormal: 356it [00:02, 176.60it/s]\n",
      "Processing slider - id_00 - normal: 1068it [00:05, 178.65it/s]\n",
      "Processing slider - id_02 - abnormal: 267it [00:01, 177.60it/s]\n",
      "Processing slider - id_02 - normal: 1068it [00:05, 178.13it/s]\n",
      "Processing slider - id_04 - abnormal: 178it [00:01, 176.59it/s]\n",
      "Processing slider - id_04 - normal: 534it [00:02, 178.36it/s]\n",
      "Processing slider - id_06 - abnormal: 89it [00:00, 177.14it/s]\n",
      "Processing slider - id_06 - normal: 534it [00:02, 178.08it/s]\n",
      "Processing valve - id_00 - abnormal: 119it [00:00, 179.20it/s]\n",
      "Processing valve - id_00 - normal: 991it [00:05, 176.66it/s]\n",
      "Processing valve - id_02 - abnormal: 120it [00:00, 179.30it/s]\n",
      "Processing valve - id_02 - normal: 708it [00:04, 176.58it/s]\n",
      "Processing valve - id_04 - abnormal: 120it [00:00, 179.99it/s]\n",
      "Processing valve - id_04 - normal: 1000it [00:05, 175.11it/s]\n",
      "Processing valve - id_06 - abnormal: 120it [00:00, 181.09it/s]\n",
      "Processing valve - id_06 - normal: 992it [00:05, 177.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from funs.download import *\n",
    "from funs.dataset import *\n",
    "from funs.utils import *\n",
    "from funs.databuilder import *\n",
    "from funs.model import STgramMFN\n",
    "from funs.trainer import Trainer\n",
    "from funs.loss import CrossEntropyLoss\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "config = load_yaml('./config.yaml')\n",
    "\n",
    "set_seed(config.seed)\n",
    "\n",
    "train_dirs = [os.path.join(config.data_dir, config.snr, train_dir) for train_dir in config.train_dirs]\n",
    "val_dirs = [os.path.join(config.data_dir, config.snr, val_dir) for val_dir in config.val_dirs]\n",
    "test_dirs = [os.path.join(config.data_dir, config.snr, test_dir) for test_dir in config.test_dirs]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "df = {}\n",
    "df = download_mimii(config.data_dir, config.snr, config.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = df['model_id'].unique()\n",
    "machine_list = df['machine_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fan-id_00': 0,\n",
       " 'fan-id_02': 1,\n",
       " 'fan-id_04': 2,\n",
       " 'fan-id_06': 3,\n",
       " 'pump-id_00': 4,\n",
       " 'pump-id_02': 5,\n",
       " 'pump-id_04': 6,\n",
       " 'pump-id_06': 7,\n",
       " 'slider-id_00': 8,\n",
       " 'slider-id_02': 9,\n",
       " 'slider-id_04': 10,\n",
       " 'slider-id_06': 11,\n",
       " 'valve-id_00': 12,\n",
       " 'valve-id_02': 13,\n",
       " 'valve-id_04': 14,\n",
       " 'valve-id_06': 15}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "\n",
    "label = 0\n",
    "for machine in machine_list:\n",
    "    for id in id_list:\n",
    "        dic[f'{machine}-{id}'] =  label\n",
    "        label += 1\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dic = make_meta2label(df)\n",
    "\n",
    "train_df, val_df, test_df = split_df(df, config.val_model_id, config.test_model_id, config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_00' 'id_04' 'id_02' 'id_06']\n",
      "['id_04' 'id_00']\n",
      "['id_06' 'id_02']\n"
     ]
    }
   ],
   "source": [
    "print(train_df['model_id'].unique())\n",
    "print(val_df['model_id'].unique()) \n",
    "print(test_df['model_id'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = build_from_dataframe(train_df)\n",
    "# val_data, val_label = build_from_dataframe(val_df)\n",
    "# test_data, test_label = build_from_dataframe(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11419"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m MIMIIDataset(train_data, train_label)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_dataset:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "File \u001b[0;32m~/Github/Deep-Learning-Study/MIMII/v3.1/funs/dataset.py:24\u001b[0m, in \u001b[0;36mMIMIIDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 24\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "train_dataset = MIMIIDataset(train_data, train_label)\n",
    "\n",
    "for i in train_dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fan-id_00', 'fan-id_00', 'fan-id_00', ..., 'valve-id_06',\n",
       "       'valve-id_06', 'valve-id_06'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(train_df['data'])\n",
    "# np.array(train_df[\"machine_type\"]+\"-\"+train_df[\"model_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-0.01203156, -0.01239395, -0.01213455, ..., -0.00082016,\n",
       "              -0.00095749, -0.00053024], dtype=float32)               ,\n",
       "       array([-0.00137329, -0.00251007, -0.00389862, ...,  0.00708008,\n",
       "               0.0063324 ,  0.00560379], dtype=float32)               ,\n",
       "       array([-0.001297  , -0.00344086, -0.00466156, ...,  0.00073624,\n",
       "               0.00021362,  0.00140762], dtype=float32)               ,\n",
       "       ...,\n",
       "       array([ 0.00022125,  0.00025558, -0.00016022, ..., -0.0045433 ,\n",
       "              -0.00326157, -0.00211334], dtype=float32)               ,\n",
       "       array([-0.00440216, -0.00170517,  0.00180817, ..., -0.00444412,\n",
       "              -0.00265121, -0.00074005], dtype=float32)               ,\n",
       "       array([-0.00255585, -0.00315094, -0.0022316 , ...,  0.00070572,\n",
       "              -0.00017166, -0.00183487], dtype=float32)               ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(train_df['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
